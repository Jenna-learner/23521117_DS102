{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65aa657",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 2 — Softmax Regression (Multiclass, NumPy-only) **No Data Leak**\n",
    "Yêu cầu:\n",
    "- **NumPy-only** để xây mô hình Softmax Regression (đa lớp: *dropout / enrolled / graduate*).\n",
    "- Huấn luyện bằng **Gradient Descent** trên bộ dữ liệu UCI *Predict students’ dropout and academic success* (ID=697).\n",
    "- **Đánh giá** mô hình (accuracy, macro P/R/F1, confusion matrix).\n",
    "- **Trực quan hóa** hàm mất mát (loss) theo epoch.\n",
    "- **Tránh mọi hình thức data leakage**: split **trước**, mọi biến đổi/loại thuộc tính/chuẩn hóa đều **fit trên train** rồi áp dụng cho test.\n",
    "- **Bổ sung**: In thông tin từng biến; vẽ **ma trận tương quan** (trên **train**); loại bỏ thuộc tính có tương quan cao (|corr| ≥ 0.9) **dựa trên train**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cấu hình\n",
    "RANDOM_SEED = 42\n",
    "TRAIN_RATIO = 0.8\n",
    "HIGH_CORR_THRESHOLD = 0.90\n",
    "LR = 0.1\n",
    "EPOCHS = 500\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "def safe_show():\n",
    "    try:\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Plot display error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7abcc5",
   "metadata": {},
   "source": [
    "## 1) Tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "ds = fetch_ucirepo(id=697)\n",
    "X = ds.data.features.copy()\n",
    "y = ds.data.targets.copy()\n",
    "\n",
    "print(\"Loaded UCI dataset 697\")\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "display(X.head(3))\n",
    "display(y.head(3))\n",
    "\n",
    "target_col = 'Target' if 'Target' in y.columns else y.columns[0]\n",
    "y_str = y[target_col].astype(str).str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a245183",
   "metadata": {},
   "source": [
    "## 2) Thông tin từng biến thành phần trong bộ dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_full = pd.concat([X.copy(), y_str.rename('Target')], axis=1)\n",
    "for col_name in df_full.columns:\n",
    "    print(\"Title:\", col_name)\n",
    "    print(\"Total NaN:\", df_full[col_name].isna().sum())\n",
    "    print(\"Total null:\", df_full[col_name].isnull().sum())\n",
    "    print(\"Data type:\", df_full[col_name].dtype)\n",
    "    print(\"*\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442bd50",
   "metadata": {},
   "source": [
    "## 3) Tạo nhãn đa lớp & Chia train/test (stratified, trước mọi biến đổi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_map = {'dropout':0, 'enrolled':1, 'graduate':2}\n",
    "def map_label(t):\n",
    "    for k,v in label_map.items():\n",
    "        if t.startswith(k):\n",
    "            return v\n",
    "    raise ValueError(\"Unknown label: \"+t)\n",
    "\n",
    "y_num = y_str.map(map_label).values\n",
    "\n",
    "# Stratified split bằng NumPy\n",
    "idx_all = np.arange(len(y_num))\n",
    "tr_idx_list, te_idx_list = [], []\n",
    "for c in np.unique(y_num):\n",
    "    idx_c = idx_all[y_num == c]\n",
    "    rng.shuffle(idx_c)\n",
    "    split = int(TRAIN_RATIO * len(idx_c))\n",
    "    tr_idx_list.append(idx_c[:split])\n",
    "    te_idx_list.append(idx_c[split:])\n",
    "\n",
    "tr_idx = np.concatenate(tr_idx_list); te_idx = np.concatenate(te_idx_list)\n",
    "rng.shuffle(tr_idx); rng.shuffle(te_idx)\n",
    "\n",
    "X_tr_df, X_te_df = X.iloc[tr_idx].copy(), X.iloc[te_idx].copy()\n",
    "y_tr, y_te = y_num[tr_idx], y_num[te_idx]\n",
    "\n",
    "print(\"Train size:\", len(y_tr), \"| Test size:\", len(y_te))\n",
    "print(\"Class dist (train):\", {k:int((y_tr==k).sum()) for k in np.unique(y_tr)})\n",
    "print(\"Class dist (test):\", {k:int((y_te==k).sum()) for k in np.unique(y_te)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b1b2e8",
   "metadata": {},
   "source": [
    "## 4) One-hot các cột phân loại (fit **trên train**, áp dụng **cho test**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = X_tr_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "X_tr_oh = pd.get_dummies(X_tr_df, columns=cat_cols, drop_first=True)\n",
    "X_te_oh = pd.get_dummies(X_te_df, columns=cat_cols, drop_first=True)\n",
    "X_te_oh = X_te_oh.reindex(columns=X_tr_oh.columns, fill_value=0)\n",
    "\n",
    "print(\"After one-hot: train =\", X_tr_oh.shape, \"| test =\", X_te_oh.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72693e",
   "metadata": {},
   "source": [
    "## 5) Ma trận tương quan (TRAIN) & loại thuộc tính tương quan cao (|corr| ≥ 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f89a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = X_tr_oh.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.set_theme(style='white')\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, cbar_kws={'shrink':0.7}, linewidths=0.2)\n",
    "plt.title(\"Correlation Matrix (TRAIN only)\", fontsize=14, pad=12)\n",
    "plt.tight_layout()\n",
    "safe_show()\n",
    "\n",
    "# Loại theo tam giác trên: mỗi cặp chỉ drop 1 cột (cột 'bên phải')\n",
    "to_drop = set()\n",
    "corr_abs = corr.abs()\n",
    "upper = corr_abs.where(np.triu(np.ones(corr_abs.shape), k=1).astype(bool))\n",
    "\n",
    "for col in upper.columns:\n",
    "    partners = [row for row, val in upper[col].items() if (not pd.isna(val)) and (val >= HIGH_CORR_THRESHOLD)]\n",
    "    if len(partners) > 0:\n",
    "        to_drop.add(col)\n",
    "\n",
    "to_drop = sorted(list(to_drop))\n",
    "print(\"Số cột bị drop do tương quan cao:\", len(to_drop))\n",
    "print(\"Preview:\", to_drop[:30])\n",
    "\n",
    "X_tr_sel = X_tr_oh.drop(columns=to_drop, errors='ignore')\n",
    "X_te_sel = X_te_oh.drop(columns=to_drop, errors='ignore')\n",
    "print(\"Shapes after drop-high-corr: train =\", X_tr_sel.shape, \"| test =\", X_te_sel.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d581ca6",
   "metadata": {},
   "source": [
    "## 6) Chuẩn hoá theo thống kê **train**, rồi áp dụng cho **test** (không leak) + thêm bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xtr_np = X_tr_sel.to_numpy(dtype=float)\n",
    "Xte_np = X_te_sel.to_numpy(dtype=float)\n",
    "\n",
    "mu  = Xtr_np.mean(axis=0, keepdims=True)\n",
    "std = Xtr_np.std(axis=0,  keepdims=True) + 1e-8\n",
    "\n",
    "Xtr = (Xtr_np - mu) / std\n",
    "Xte = (Xte_np - mu) / std\n",
    "\n",
    "Xtr = np.hstack([np.ones((Xtr.shape[0],1)), Xtr])\n",
    "Xte = np.hstack([np.ones((Xte.shape[0],1)), Xte])\n",
    "\n",
    "print(\"Final matrices:\", Xtr.shape, Xte.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b99ba",
   "metadata": {},
   "source": [
    "## 7) Huấn luyện Softmax Regression (NumPy-only, Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee087ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = len(np.unique(y_tr))\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "def one_hot(y, K):\n",
    "    oh = np.zeros((len(y), K))\n",
    "    oh[np.arange(len(y)), y] = 1.0\n",
    "    return oh\n",
    "\n",
    "def nll_loss(logits, y):\n",
    "    p = softmax(logits)\n",
    "    return -np.mean(np.log(p[np.arange(len(y)), y] + 1e-12))\n",
    "\n",
    "n, d = Xtr.shape\n",
    "W = np.zeros((d, K))\n",
    "Ytr = one_hot(y_tr, K)\n",
    "\n",
    "losses = []\n",
    "for ep in range(EPOCHS):\n",
    "    logits = Xtr @ W\n",
    "    probs = softmax(logits)\n",
    "    loss = nll_loss(logits, y_tr)\n",
    "    losses.append(loss)\n",
    "    grad = (Xtr.T @ (probs - Ytr)) / n\n",
    "    W -= LR * grad\n",
    "    if (ep+1) % 50 == 0:\n",
    "        print(f\"Epoch {ep+1}/{EPOCHS} | loss={loss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ded522",
   "metadata": {},
   "source": [
    "## 8) Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(W, X):\n",
    "    return np.argmax(softmax(X @ W), axis=1)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return (y_true == y_pred).mean()\n",
    "\n",
    "def prf_macro(y_true, y_pred, K):\n",
    "    P, R, F = [], [], []\n",
    "    for k in range(K):\n",
    "        tp = np.sum((y_true==k) & (y_pred==k))\n",
    "        fp = np.sum((y_true!=k) & (y_pred==k))\n",
    "        fn = np.sum((y_true==k) & (y_pred!=k))\n",
    "        prec = tp / (tp+fp+1e-12)\n",
    "        rec  = tp / (tp+fn+1e-12)\n",
    "        f1   = 2*prec*rec / (prec+rec+1e-12)\n",
    "        P.append(prec); R.append(rec); F.append(f1)\n",
    "    return np.mean(P), np.mean(R), np.mean(F)\n",
    "\n",
    "yhat_tr = predict(W, Xtr)\n",
    "yhat_te = predict(W, Xte)\n",
    "\n",
    "Pm, Rm, Fm = prf_macro(y_te, yhat_te, K)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = np.zeros((K,K), dtype=int)\n",
    "for t,p in zip(y_te, yhat_te):\n",
    "    cm[t,p]+=1\n",
    "\n",
    "print(\"Train Acc:\", accuracy(y_tr, yhat_tr))\n",
    "print(\"Test  Acc:\", accuracy(y_te, yhat_te))\n",
    "print(f\"Macro P/R/F1 (test): {Pm:.3f}/{Rm:.3f}/{Fm:.3f}\")\n",
    "print(\"Confusion matrix (test):\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b9c1b",
   "metadata": {},
   "source": [
    "## 9) Đồ thị hàm mất mát (Loss) theo epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd08599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(losses)+1), losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"NLL Loss\")\n",
    "plt.title(\"Training Loss (Softmax Regression, NumPy-only, No Leak)\")\n",
    "plt.tight_layout()\n",
    "safe_show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
